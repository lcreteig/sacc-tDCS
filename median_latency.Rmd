---
title: "Transcranial direct current stimulation of the right frontal eye field in a prosaccade task"
author: Leon Reteig
subtitle: Median latency analysis
output:
  html_notebook:
    highlight: pygments
    toc: true
    toc_float: true
---

R notebook for analyses of median saccade latency in the `sacc-tDCS` dataset. Previous processing:

* Raw data were parsed into events (saccades, fixations, etc.) by the EyeLink data were collected on.
* Events were extracted and saccade measures were computed with a MATLAB script.

```{r setup}
# Load some libraries
library(tidyverse) # importing, transforming, and visualizing data frames
library(ez) # ANOVA
library(BayesFactor) # Bayesian statistics
library(broom) # transform model output into a data frame
library(knitr) # R markdown output (html, pdf, etc.)
opts_chunk$set(message = FALSE, warning = FALSE) # Don't show warnings and messages in HTML output

source("src/lib/InclusionBF.R")

sessionInfo()
```

# Load data

## Eye data

The .csv file with the eye tracking data was created in MATLAB.

```{r Load the data frame}
# Load the data frame
dataFile <- file.path("data", "sacc-tDCS_data.csv")
groupData <- read_csv(dataFile, col_names = TRUE, na = "NaN", progress = FALSE, col_types = cols(
  stimulation = col_factor(c("anodal","cathodal")),
  leg = col_factor(c("pre","tDCS","post")),
  type = col_factor(c("lateral","center")),
  direction = col_factor(c("left","right")) 
))
```

```{r Show data frame}
kable(head(groupData))
```

* __subject__: subject ID
* __stimulation__: Whether data are from the `anodal` or `cathodal` session
* __leg__: Whether data are before (`pre`), during (`tDCS`), or after (`post`) tDCS
* __block__: After each block participant had a brief break and tracker was recalibrated
* __trial__: trial number within a block
* __type__:
    * `lateral` - fixation in center of display, saccade made towards the periphery
    * `center` - fixation in periphery, saccade made back towards the center of the display
* __direction__: `left` for saccades towards the left of current fixation position; `right` for saccades to the right
* __deviation.start__ : distance (in visual angle) from saccade start point to fixation
* __deviation.end.x__: distance (in visual angle) from x-coordinate of saccade end point to x-coordinate of target location
* __deviation.end.y__: same for y-coordinate
* __amplitude__: distance (in visual angle) between saccade start and end point
* __latency__: time (in ms) from target onset to start of saccade
* __drift.x__: distance (in visual angle) between x-coordinate of average fixation position during the break to x-coordinate of fixation stimulus. This stimulus was displayed at each break in the task, so this data can be used as an estimate of offsets to do drift correction.
* __drift.y__: same for y-coordinate

```{r Load subject info data}
# Load eye tracking data into data frame
dataFile <- file.path("data", "subject_info.csv")
subjectData <- read_csv2(dataFile, col_names = TRUE, progress = FALSE, col_types = cols(
  session.order = col_factor(c("first.anodal", "first.cathodal"))
))
```

## Subject metadata

```{r Show subject info data frame, results='asis'}
kable(head(subjectData))
```

* __subject__: subject ID
* __session.order__: Whether subject had anodal stimulation in the first session (`first.anodal`) or cathodal stimulation in the first session (`first.cathodal`)
* __gender__
* __age__: in years
* __dominant.eye__: result of eye dominance test

The main use is to see if the nuisance factor _session.order_ covaries with the factors of interest in the design. This could indicate the presence of carryover effects between the stimulation, or a difference in subgroups within the sample (see <http://www.jerrydallal.com/lhsp/crossovr.htm> for an introduction to these kinds of analyses.).

# Inspect median data

## Remove outliers

```{r Outlier criteria}
tooFast <- 50
tooSlow <- 400
badFix <- 1.8
badSacc <- 8
subs2exclude <- c("S28","S16","S22","S21","S25")
```

* S21 and S25 were tested < 48h apart
* S16, S22 and S28 had fewer than 50 saccades per condition after trial rejection

Criteria for outlier saccades:

* Discard fast saccades, with a latency of `r tooFast` ms or less
* Discard slow saccades, saccades with a latency of `r tooSlow` ms or more
* Discard inaccurate fixations, with saccade starting point more than `r badFix` degrees or more away from fixation
* Discard faulty saccades, with x-coordinate of saccade end point `r badSacc` degree or more away from the target

In [Kanai et al. (2012)](http://dx.doi.org/10.3389/fpsyt.2012.00045), this was:

* Fast saccades: 50 ms
* Slow saccades: 400 ms
* Bad fixations: 1.8 degrees
* Faulty saccades: opposite hemifield of target (here, that would be 8 degrees as targets were that eccentric)

```{r Remove outlier trials and subjects}
# Remove outliers and subjects
groupData <- filter(groupData,
                    # outliers
                    latency >= tooFast,
                    latency <= tooSlow,
                    deviation.start <= badFix,
                    deviation.end.x <= badSacc,
                    # subjects
                    !(subject %in% subs2exclude),
                    # missing values
                    complete.cases(groupData)
)
```

## Data per block

```{r Compute median in each condition}
# Compute median in each condition
latencyMedian <- groupData %>%
  group_by(subject,stimulation,leg,block,type,direction) %>%
  summarise(latency = median(latency))
```

### Full factorial plot

```{r Full factorial plot}
# Plot out all the data
fullPlot <- ggplot(latencyMedian, aes(interaction(block,leg), latency, color = stimulation, shape = stimulation)) +
  facet_grid(type ~ direction) +
  stat_summary(fun.y = mean, geom = "point", size = 3) +
  stat_summary(fun.y = mean, geom = "line", aes(group = stimulation), size = 1)
fullPlot
```

For some reason cathodal is always a little faster than anodal. There is probably a few ms difference between them on average, also in the baseline block. This is clearly just random variation, but it could be a problem, since the effects we expect are not much bigger...

The above plot also shows a lot of variability, so it might be best to average over each 3 consecutive blocks so the data come in 15-minute intervals.

## 15-minute intervals (collapse 3 blocks)

```{r Compute median, collapsed across blocks}
# Compute median per leg
latencyMedianLeg <- groupData %>%
  group_by(subject,stimulation,direction,type) %>% 
  summarise(baseline = median(latency[leg == "pre"]), # take average of 3 blocks, make new column
            tDCS = median(latency[leg == "tDCS"]),
            post.1 = median(latency[leg == "post" & block <= 3]),
            post.2 = median(latency[leg == "post" & block >= 4])) %>%
 gather(leg,latency,baseline,tDCS,post.1,post.2) %>% # gather new columns to use as factor
 mutate(leg = factor(leg, levels = c("baseline", "tDCS", "post.1", "post.2"))) # reorder factor levels
```

### Line plot per leg, individual subjects

Now make the same plot, but for the data collapsed over 3 blocks. Also draw the plot for each individual subject, so we can see which subjects drive the baseline difference, and in which direction the stimulation effect goes for each subject (if there is any).

```{r Line plot for each subject, fig.height= 6}
kanaiSubsPlot <- ggplot(latencyMedianLeg, aes(leg, latency, color = stimulation, shape = type)) +         
  facet_wrap(~subject, ncol = 5) +
  stat_summary(fun.y = mean, geom = "point", size = 2) +
  stat_summary(fun.y = mean, geom = "line", aes(group = stimulation))
kanaiSubsPlot
```

There are a couple of subjects that show large differences in the baseline already, especially S01. The stimulation effects seem to not be very apparent, but they could also drown out at this scale.

### Compute magnitude of baseline difference

Let's look at the size of the baseline difference per subject. 

```{r results = 'asis'}
baselineDiff <- latencyMedianLeg %>% 
  filter(leg == "baseline") %>% # keep only baseline data
  spread(stimulation, latency) %>% # make separate columns for anodal and cathodal
  mutate(latency.diff = anodal - cathodal) %>% # subtract the difference
  group_by(subject) %>% 
  summarise(latency.diff = mean(latency.diff))# keep the average difference per subject

kable(baselineDiff, caption = 'Difference between baseline saccade latencies in anodal and cathodal session')
```

There are a few subjects with substantial latency differences between sessions, so it's probably a good idea to subtract the baseline for the statistical analyses. The mean difference is `r round(mean(baselineDiff$latency.diff), digits = 1)` ms. So on average, the cathodal session is a little faster, so the counterbalancing is not perfect, but the difference is not very high.


# Median reaction time plots and analyses

Here we simply extract median RTs for each condition and use a repeated measures ANOVA for statistical analysis, following [Kanai et al. (2012)](http://dx.doi.org/10.3389/fpsyt.2012.00045).

## Line plot per leg over all subjects

Let's look at the group average plot for the first time.

```{r Line plot per leg}
kanaiPlot <- ggplot(latencyMedianLeg, aes(leg, latency, color = stimulation, shape = stimulation)) +         
  facet_grid(type ~ direction) +
  stat_summary(fun.y = mean, geom = "point", size = 3) +
  stat_summary(fun.y = mean, geom = "line", aes(group = stimulation), size = 1) +
  stat_summary(fun.data = mean_cl_normal, geom = "errorbar", width = 0.3)
kanaiPlot
```

All differences between anodal & cathodal seem to be < 5 ms. Any differences that are there also 1) do not seem to differ much between the time blocks, or 2) be in the opposite direction for anodal and cathodal, with the possible exception of the first post-block in the center-right condition.

### Individual subjects

#### Anodal session

Let's look at the same plot for individual subjects, to see whether there are any consistent patterns or huge outliers there.

```{r Line plot per subject - anodal}
kanaiPlotSubsAnodal <- ggplot(latencyMedianLeg[latencyMedianLeg$stimulation == "anodal", ], aes(leg, latency)) +
  facet_grid(type ~ direction) +
  geom_line(aes(group=subject,color=subject)) +
  stat_summary(fun.y = mean, aes(group = stimulation), geom = "line") +
  stat_summary(fun.y = mean, geom = "point") +
  ggtitle("Anodal session")
kanaiPlotSubsAnodal
```

There do appear to be some "outliers", but they are fairly well balanced (below or above the average), and >80% or so of subjects seem to cluster together. I don't see much evidence for systematic individual differences (e.g. slow subjects get faster; fast subjects get slower.)

#### Cathodal session

```{r Line plot per subject - cathodal}
kanaiPlotSubsCathodal <- ggplot(latencyMedianLeg[latencyMedianLeg$stimulation == "cathodal", ], aes(leg, latency)) +
  facet_grid(type ~ direction) +
  geom_line(aes(group=subject,color=subject)) +
  stat_summary(fun.y = mean, aes(group = stimulation), geom = "line") +
  stat_summary(fun.y = mean, geom = "point") +
  ggtitle("Cathodal session")
kanaiPlotSubsCathodal
```

There seem to be less clear individual outliers, but the spread also seems a bit bigger (e.g. right-lateral)

## Subtract baseline

Baseline differences (while small here) are not informative and could obscure real changes from baseline within subjects. Also it's hard to see and compare the magnitude of the effects, also for instance because center saccades are much faster than lateral saccades. Therefore, subtract the baseline from each subsequent measurement.

```{r Subtract baseline}
latencyMedianBaseline <- latencyMedianLeg %>%
  group_by(subject,stimulation,direction,type) %>% # for each condition, subtract baseline scores and make new columns
  summarise(tDCS = latency[leg == "tDCS"] - latency[leg == "baseline"], 
           post.1 = latency[leg == "post.1"] - latency[leg == "baseline"],
           post.2 = latency[leg == "post.2"] - latency[leg == "baseline"]) %>%
  gather(leg, latency, tDCS, post.1, post.2)  %>% # gather new columns to use as factor 
  mutate(leg = factor(leg, levels = c("tDCS", "post.1", "post.2"))) # reorder factor levels
```

### Baseline data

Before we look at the change-from-baseline data, it would be good to check the baseline data itself.

#### Baseline reliability

Analyzing change-from-baseline only makes sense if the baseline data are not very noisy. Subtracting a noisy measure from the data will increase the noise in the data, and thereby [reduce power](http://datacolada.org/39). One way to assess this is to look at the correlation between the baseline blocks in both sessions. If there is a high correlation, the pro-saccade task produces comparable latencies each time it is performed, and thus the baseline data should on average not be very noisy.

Let's compute the correlation between all baselines (i.e. for the factors DIRECTION and TYPE).

```{r baseline correlations}
baselineCorr <- latencyMedianLeg %>%
  filter(leg == "baseline") %>% # keep only baseline data
  group_by(direction,type) %>% # for each of these 4 pairs
  spread(stimulation,latency) %>% # make 2 columns with baseline latencies of anodal and cathodal session
  nest() %>% # create a separate data frame of all remaining columns. These data frames are stored in a list-column named "data"
  mutate(stats = map(data, ~cor.test(formula = ~ anodal + cathodal, data =.))) %>% # run correlation test on baselines from each condition
  mutate(tidy_model = map(stats, tidy)) %>% # force the four test outputs to also be data frames in a list column ("tidy_model")
  unnest(tidy_model, .drop = TRUE)  # unpack the list-column with results, drop the list-column we used to organize the data
```

Now a scatter plot of the data, with the results of the test:

```{r baseline scatterplots}
latencyMedianLeg %>%
  filter(leg == "baseline") %>%
  spread(stimulation,latency) %>%
  inner_join(., subjectData[ ,c("subject","session.order")], by = c("subject")) %>% # add column on session order from other data frame
  ggplot(aes(anodal,cathodal)) +
    facet_grid(type ~ direction) +
    geom_abline(intercept = 0, slope = 1, linetype = "dashed") +
    geom_smooth(method = "lm") +
    geom_point(aes(color=session.order)) +
    xlim(80,220) + ylim(80,220) +
    geom_text(data = baselineCorr, x = 100, y = 200, aes(label = paste("italic(r) == ", round(estimate,2))), parse = TRUE) +
    labs(title = "Baseline in anodal and cathodal sessions", subtitle = "scatterplot of baseline latencies")
```

The correlations are quite high, at least high enough for the baseline subtraction to help power rather than hurt (r's > 0.5).

There are a few outliers though: some subjects deviate quite a bit from the idealized line (dashed).

When the data is split for session order, a clear pattern becomes apparent: latencies are generally faster in the 2nd session (for those who got cathodal first, are above the diagonal, meaning anodal < cathodal. The reverse pattern is visible for those who received anodal first). So in that sense there is a difference between two groups of subjects.

#### Baseline differences

If the prosaccade task is indeed reliable, there shouldn't be any significant differences at the group-level between the baseline blocks of both sessions. If there are, this may be problematic, because all the change-scores are expressed relative to the baseline. A significant difference between two conditions in later blocks could then be driven by the differences that already occur in the baseline.

Let's plot the baseline scores in each session for each subject:

```{r baseline linked stripchart}
latencyMedianLeg %>%
  filter(leg == "baseline") %>%
  ggplot(aes(stimulation, latency)) +
    facet_grid(type ~ direction) +
    stat_summary(fun.y = mean, geom = "line", aes(group = 1), size = 1.5) +
    geom_line(aes(group = subject, colour = subject), alpha = 0.5, position = position_dodge(width = 0.1)) +
    labs(title = "Baseline in anodal and cathodal sessions", subtitle = "linked stripchart of baseline latencies")
```

Most lines appear fairly flat. However, there is quite some variability around the mean, and some subjects show quite a steep difference. There appears to be some sort of regression to the mean also: extreme scores in either session show a steeper slope than those scores that are less extreme.

Let's look at the pairwise differences in more detail:

```{r baseline difference stripchart}
latencyMedianLeg %>%
  filter(leg == "baseline") %>%
  inner_join(., subjectData[ ,c("subject","session.order")], by = c("subject")) %>% # add column on session order from other data frame
  group_by(subject,direction,type,session.order) %>%
  summarise(latency.diff = latency[stimulation == "anodal"] - latency[stimulation == "cathodal"]) %>%
  ggplot(aes(factor(0), latency.diff)) +
    facet_grid(type ~ direction) +
    geom_hline(yintercept = 0, linetype = "dashed") +
    stat_summary(fun.data = mean_cl_normal) +
    stat_summary(fun.y = mean, aes(label=round(..y.., digits=2), x = 1.3), geom = "label", alpha = 0.5) +
    geom_point(shape = 21, aes(colour = session.order), position = position_jitter(width=.1)) +
    labs(title = "Baseline in anodal and cathodal sessions", subtitle = "anodal - cathodal")
```

The sequence effect we observed earlier is very clear when we split the data by session order again, particularly in the lateral condition (i.e. latencies are always faster in the 2nd session).

Somewhat worryingly, the baseline differences are in the range of the tDCS effect size we expect, particularly in the center condition. That said, the differences do cluster around 0, there are really only a few subjects that fall far outside the boundary (one is really extreme). 

The CIs appear to overlap with 0 though, so the differences shouldn't be significant. Let's test that:

```{r t-tests of baseline difference}
latencyMedianLeg %>%
  filter(leg == "baseline") %>%
  group_by(direction,type) %>% # for each of these 4 pairs
  nest() %>% # create a separate data frame of all remaining columns. These data frames are stored in a list-column named "data"
  mutate(stats = map(data, ~t.test(formula = latency~stimulation, paired = TRUE, data =.))) %>% # run t-test on the data frames
  mutate(tidy_model = map(stats, tidy)) %>% # force the four test outputs to also be data frames in a list column ("tidy_model")
  unnest(tidy_model, .drop = TRUE) %>% # unpack the list-column with results, drop the list-column we used to organize the data
  kable(.)
```

Indeed, they are not, although the center conditions come close.

### Line plots per leg from baseline

```{r Line plot from baseline}
kanaiPlotBase <- ggplot(latencyMedianBaseline, aes(leg, latency, color = stimulation, shape = stimulation)) +         
  facet_grid(type ~ direction) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  stat_summary(fun.y = mean, geom = "point", size = 3) +
  stat_summary(fun.y = mean, geom = "line", aes(group = stimulation), size = 1) +
  stat_summary(fun.data = mean_cl_normal, geom = "errorbar", width = 0.3) +
  coord_cartesian(ylim = c(-10,10))
kanaiPlotBase
```

Generally the differences between the stimulation conditions are small (< 4 ms). Except for the center-left condition, but this condition also had the largest baseline difference...

### Individual subjects

#### Anodal session

```{r Line plot from baseline per subject - anodal}
kanaiPlotBaseSubsAnodal <- ggplot(latencyMedianBaseline[latencyMedianBaseline$stimulation == "anodal", ], aes(leg, latency)) +
  facet_grid(type ~ direction) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_line(aes(group=subject,color=subject)) +
  stat_summary(fun.y = mean, aes(group = stimulation), geom = "line") +
  stat_summary(fun.y = mean, geom = "point") + 
  ggtitle("Anodal difference from baseline")
kanaiPlotBaseSubsAnodal
```

#### Cathodal session

```{r Line plot from baseline per subject - cathodal}
kanaiPlotBaseSubsCathodal <- ggplot(latencyMedianBaseline[latencyMedianBaseline$stimulation == "cathodal", ], aes(leg, latency)) +
  facet_grid(type ~ direction) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_line(aes(group=subject,color=subject)) +
  stat_summary(fun.y = mean, aes(group = stimulation), geom = "line") +
  stat_summary(fun.y = mean, geom = "point") + 
  ggtitle("Cathodal difference from baseline")
kanaiPlotBaseSubsCathodal
```

All of this is split pretty much 50-50, hence the average difference hovering around 0.

# Statistics

```{r Prepare data frames}
# Make "subject" a factor, so we can model the repeated measures
latencyMedianBaseline <- latencyMedianBaseline %>%
  ungroup() %>% # remove grouping info, because we need to refactor
  inner_join(., subjectData[ ,c("subject","session.order")], by = c("subject")) %>% # add column from on session order from other data frame
  mutate(subject = factor(subject)) # refactor

latencyMedianLeg <- latencyMedianLeg %>%
  ungroup() %>%
  inner_join(., subjectData[ ,c("subject","session.order")], by = c("subject")) %>% # add column from on session order from other data frame
  mutate(subject = factor(subject))
```

## Frequentist 

### Omnibus anova - saccade latency

__Data__: Outlier trials removed, collapsed into 15-minute intervals. 

__Dependent measure__: saccadic latency

__Factors__:

* STIMULATION (anodal vs. cathodal)
* LEG (baseline, tDCS, post.1, post.2)
* TYPE (lateral vs. center)
* DIRECTION (left vs. right)

```{r Omnibus ANOVA, results='asis'}
modelOmni <- ezANOVA(data = data.frame(latencyMedianLeg), # Repeated over subjects; type 3 sums of squares (cf. SPSS)
                        dv = .(latency), wid = .(subject), within = .(stimulation, leg, type, direction), type = 3)
kable(modelOmni)
```

#### Main effect: type

```{r Omni Main effect of type}
latencyMedianLeg %>%
  group_by(subject,type) %>%
  summarise(latency = mean(latency)) %>%
  ggplot(aes(type, latency)) +
  stat_summary(fun.data = mean_cl_normal, size = 1) +
  geom_jitter(width = 0.25)
```

This simply reflects that center saccades are faster than lateral saccades, because the location of the target is known.

#### Interaction: leg by type

```{r Omni Interaction leg by type}
latencyMedianLeg %>%
  group_by(subject,leg,type) %>%
  summarise(latency = mean(latency)) %>%
  ggplot(aes(leg, latency, shape = type)) +
  stat_summary(fun.y = mean, geom = "point") +
  stat_summary(fun.y = mean, geom = "line", aes(group = type, linetype = type))
```

The effect of Type changes over time: lateral saccades steadily become slower; center saccades vary more randomly.

#### Interaction: leg by type by direction

```{r Omni Interaction leg by type by direction}
latencyMedianLeg %>%
  group_by(subject,leg,type,direction) %>%
  summarise(latency = mean(latency)) %>%
  ggplot(aes(leg, latency, shape = type)) +
  facet_wrap(~direction) +
  stat_summary(fun.y = mean, geom = "point") +
  stat_summary(fun.y = mean, geom = "line", aes(group = type, linetype = type))
```

The effect over time looks non-linear for left-center saccades. The "tDCS" block is the deviant here, but there is no interaction with stimulation.

Also, for right-lateral saccades, there is a big change that only emerges in the 2nd post-block.

### ANOVA matching Kanai et al. (2012) - lateral saccades {.tabset .tabset-fade}

#### Without session order

Differing from the previous omnibus analysis, [Kanai et al. (2012)](http://dx.doi.org/10.3389/fpsyt.2012.00045) analysed shifts from baseline and only had lateral saccades.

__Data__: 

* Outliers removed
* Collapsed into 15-minute intervals
* Subtract the baseline from each subsequent block
* Discard center, keep only lateral saccades

__Dependent measure__: saccadic latency

__Factors__:

* STIMULATION (anodal vs. cathodal)
* LEG (tDCS, post.1, post.2)
* DIRECTION (left vs. right)

```{r Kanai ANOVA, results='asis'}

modelKanai <- ezANOVA(data = data.frame(filter(latencyMedianBaseline, type == "lateral")),
                        dv = .(latency), wid = .(subject), within = .(stimulation,leg,direction), type = 3)

# OR, without the EZ package:
# modelKanai=aov(latency~stimulation*leg*direction + Error(subject/(stimulation*leg*direction)),data=latencyMedianBaselineLateral)
# summary(modelKanai)

kable(modelKanai)
```

##### Main effect of leg

```{r Kanai Main effect of leg}
latencyMedianBaseline %>%
  filter(type == "lateral") %>%
  group_by(subject,leg) %>%
  summarise(latency = mean(latency)) %>%
  ggplot(aes(leg, latency)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  stat_summary(fun.data = mean_cl_normal, size = 1) +
  stat_summary(fun.y = mean, geom = "line", aes(group = 1)) +
  geom_jitter(width = 0.25)
```

Saccades become slower over time with respect to the baseline. Note that this effect becomes just non-significant when correcting for sphericity.

##### Interaction: Leg by direction

```{r Kanai Interaction leg by direction}
latencyMedianBaseline %>%
  filter(type == "lateral") %>%
  group_by(subject,leg,direction) %>%
  summarise(latency = mean(latency)) %>%
  ggplot(aes(leg, latency, shape = direction)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  stat_summary(fun.y = mean, geom = "point") +
  stat_summary(fun.y = mean, geom = "line", aes(group = direction, linetype = direction))
```

This main effect of leg is stronger for right saccades, but does not occur until the 2nd post-block.

##### Interaction: stimulation by leg by direction

This interaction is not significant, but it is of primary interest, so let's still look at it in more detail.

```{r Kanai Interaction stimulation by leg by direction}
latencyMedianBaseline %>%
  filter(type == "lateral") %>%
  group_by(subject,stimulation,leg,direction) %>%
  summarise(latency = mean(latency)) %>%
  ggplot(aes(leg, latency, shape = stimulation, color = stimulation)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  facet_wrap(~direction) +
  stat_summary(fun.y = mean, geom = "point") +
  stat_summary(fun.y = mean, geom = "line", aes(group = stimulation))
```

Interestingly, subjects get slower over time in all conditions, but this trend is reversed for left-saccades in the anodal session, as predicted. However, the effect barely reaches 1 ms...

#### With session order

Add an additional factor SESSION ORDER, which creates two groups: those subjects who received anodal tDCS in the first session vs. those who received cathodal tDCS in the first session. Note that these groups are not exactly balanced, which might affect (correcting for) violations of sphericity:

```{r Unbalanced session orders, results='asis'}
latencyMedianBaseline %>%
  group_by(session.order) %>%
  summarize(count = n_distinct(subject)) %>%
  kable(.)
```

__Data__: 

* Outliers removed
* Collapsed into 15-minute intervals
* Subtract the baseline from each subsequent block
* Discard center, keep only lateral saccades

__Dependent measure__: saccadic latency

__Factors__:

* STIMULATION (anodal vs. cathodal)
* LEG (tDCS, post.1, post.2)
* DIRECTION (left vs. right)
* SESSION ORDER (first anodal vs. first cathodal)

```{r Kanai ANOVA lateral session order, results='asis'}
modelKanaiOrder <- ezANOVA(data = data.frame(filter(latencyMedianBaseline, type == "lateral")), dv = .(latency), 
          wid = .(subject), within = .(stimulation,leg,direction),  between = session.order, type = 3)
kable(modelKanaiOrder)
```

##### Interaction: session order by stimulation by direction

```{r Kanai Interaction session order by stimulation by direction}

latencyMedianBaseline %>%
  filter(type == "lateral") %>%
  group_by(subject,session.order,stimulation,direction) %>%
  summarise(latency = mean(latency)) %>%
  ggplot(aes(direction, latency, shape = stimulation, color = stimulation)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  facet_wrap(~session.order) +
  stat_summary(fun.y = mean, geom = "point") +
  stat_summary(fun.y = mean, geom = "line", aes(group = stimulation))
```

The session order by stimulation direction interaction can be construed as a main effect of session. It appears that in the 2nd session, people slow down more than in the 1st. The difference between left and right also seems more pronounced, especially when the 2nd session is anodal.

This latter three-way interaction is very difficult to interpret though. In addition, the stimulation by direction interaction is not significant without session order, so we do not have to worry that this effect is present but confounded by session order.

### ANOVA matching Kanai et al. (2012) - center saccades {.tabset .tabset-fade}

#### Without session order

Repeat the same ANOVA, but now for center saccades (which Kanai did not have).

```{r Kanai ANOVA center, results='asis'}

modelKanaiCenter <- ezANOVA(data = data.frame(filter(latencyMedianBaseline, type == "center")),
                        dv = .(latency), wid = .(subject), within = .(stimulation,leg,direction), type = 3)

kable(modelKanaiCenter)
```

##### Main effect of direction

```{r Kanai-Center Main effect of direction}
latencyMedianBaseline %>%
  filter(type == "center") %>%
  group_by(subject,direction) %>%
  summarise(latency = mean(latency)) %>%
  ggplot(aes(direction, latency)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  stat_summary(fun.y = mean, geom = "line", aes(group = 1), size = 2) +
  geom_line(aes(colour = subject, group = subject))
```

This seems to be a really tiny and variable effect, but apparently left saccades get somewhat slower and right saccades somewhat faster compared to baseline.

#### With session order

```{r Kanai ANOVA center session order, results='asis'}
modelKanaiCenterOrder <- ezANOVA(data = data.frame(filter(latencyMedianBaseline, type == "center")), dv = .(latency), 
          wid = .(subject), within = .(stimulation,leg,direction),  between = session.order, type = 3)
kable(modelKanaiCenterOrder)
```

###### Interaction: session order by direction

There is a main effect of direction in the ANOVA without session order, so this effect might be confounded.

```{r Kanai-Center-Session-order Interaction with direction}
latencyMedianBaseline %>%
  filter(type == "center") %>%
  group_by(subject,session.order,direction) %>%
  summarise(latency = mean(latency)) %>%
  ggplot(aes(direction, latency, shape = session.order)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  stat_summary(fun.y = mean, geom = "point") +
  stat_summary(fun.y = mean, geom = "line", aes(group = session.order, linetype = session.order))
```

The main effect of direction is present for both groups, but it is much stronger in the group that first receives cathodal stimulation. This could be construed as a _carryover_ effect, i.e. that the effect of cathodal stimulation was not yet washed-out by the second session and modulated the effect of anodal (and vice versa). Or, it could simply be that there is a difference between the two groups (anodal first vs. cathodal first) that has nothing to do with stimulation.

## Bayesian

### Linear mixed effects matching Kanai - saccade latency

#### Test against the null model

```{r Compute Bayes Factors cf. null model}
bfKanaiLateral = anovaBF(latency~stimulation*leg*direction+subject, data = data.frame(filter(latencyMedianBaseline, type == "lateral")), whichModels = "withmain", whichRandom = "subject", progress = FALSE, iterations = 100000) # compute Bayes Factors
bfKanaiLateral = sort(bfKanaiLateral, decreasing = TRUE) # sort such that winning model is at the top
```

First we compare all models to the most simple (null) model, which is the intercept only + random effect model: `latency ~ subject`. This does not test for effects of SUBJECT but models it as a nuisance factor (`whichRandom = "subject"`). In addition, to decrease the model space, we do not consider models that have an interaction without the corresponding main effects (`whichModels = "withmain"`).

```{r Extract Bayes Factors withMain, results='asis'}
kable(select(extractBF(bfKanaiLateral), bf)) # show only the Bayes factors in a table
```

The winning model is the one with just a main effect of LEG, with a Bayes factor of `r round(extractBF(bfKanaiLateral[1], onlybf = TRUE), digits = 1)`. However, so even for this model there is less evidence than for the null model, which by definition has a Bayes Factor of 1.

The conventional interpretation for Bayes Factors is the following:

* $BF_{10}$ < 0.1: strong evidence for H0
* 0.1 < $BF_{10}$ < .33: moderate evidence for H0
* 0.333 < $BF_{10}$ < 1: anecdotal evidence for H0

* $BF_{10}$ = 1: equivalent evidence for H0 and H1

* 1 $BF_{10}$ < 3: anecdotal evidence for H1
* 3 < $BF_{10}$ < 10: moderate evidence for H1
* $BF_{10}$ > 10: strong evidence H1 

So to switch between expressing the Bayes Factor as evidence for H1 ($BF_{10}$) or H0 ($BF_{01}$), you simply invert it (divide by 1).

We can compute the evidence for a particular effect by comparing this winning model with the best-fitting model that does _not_ contain the effect. We can compute the evidence for _absence_ of a particular effect by comparing the winning model with the best-fitting model that _does_ contain the effect.

The evidence for the effect of LEG can be quantified by comparing the Bayes factors of the first and the 3rd model (because that is the first one that does _not_ contain LEG as a factor): `r round(extractBF(bfKanaiLateral[1] / bfKanaiLateral[3], onlybf = TRUE), digits = 1)`. This constitues only anocdotal evidence for the presence of a leg effect, even though it was significant in the classical ANOVA. But, given that the leg model itself is such a poor fit, in the Bayesian analysis this weak evidence is no surprise.

The evidence for the _absence_ of the STIMULATION by DIRECTION interaction can be quantified by comparing the Bayes factors of the first and the 9th model (because that is the first one that _does_ contain the interaction): `r round(extractBF(bfKanaiLateral[1] / bfKanaiLateral[9], onlybf = TRUE), digits = 1)`. This constitues strong evidence for the absence of the interaction.

#### Test against the full model

Another option for quantifying evidence for a particular effect is to compare the full model to a model where that effect is omitted (`whichModels = top")`. The full model is `stimulation + direction + stimulation:direction + leg + stimulation:leg + direction:leg + stimulation:direction:leg + subject`.

```{r Compute Bayes Factors cf. full model}
bfKanaiLateralFull = anovaBF(latency~stimulation*leg*direction+subject, data = data.frame(filter(latencyMedianBaseline, type == "lateral")), whichModels = "top", whichRandom = "subject", progress = FALSE, iterations = 100000) # compute Bayes Factors
bfKanaiLateralFull
```

Removing the LEG effect from the model yields a higher Bayes Factor, so removing this effect actually improved the model, although only by a little bit. The evidence thus goes in the direction of the null; when expressed in favor of the alternative, the Bayes Factir becomes less than one: 1 \ `r round(extractBF(bfKanaiLateralFull[5], onlybf = TRUE), digits = 3)` ` = ` `r round(extractBF(1/bfKanaiLateralFull[5], onlybf = TRUE), digits = 1)` 

Similarly, removing the DIRECTION by STIMULATION effect improves the model, and this time a bit more: in the range of moderate evidence for the null.

#### Bayesian model averaging

The problem with the 1st option (comparing single models, for example to the winning model) is that for designs with many factors (and therefore models), it becomes risky and a bit subjective to base conclusions on just two models. In this case, the winning model is even a bad fit, so it doesn't seem appropriate to use it as a benchmark.

The problem with the 2nd option (comparing against the full model) is actually very apparent in this dataset: the full model is a terrible fit, as it comes in last. There is even a lot of evidence against it when compared to the null model!

One solution is to do Bayesian Model Averaging: compare multiple models and aggregate the Bayes Factors.

In the [JASP stats package](http://jasp-stats.org), this analysis is also called the "inclusion Bayes factor". Briefly, it compares all models that include the effect of interest vs. all models that do not. For examples and a conceptual explanation, see example 5 in: [Bayesian inference for psychology. Part II: Example applications with JASP](https://doi.org/10.3758/s13423-017-1323-7).

There's also a different way of calculating inclusion Bayes factors ([conceptualized by Sebastiaan Mathot](https://www.cogsci.nl/blog/interpreting-bayesian-repeated-measures-in-jasp)) that is currently being implemented in JASP. This is called the "inclusion Bayes factor across matched models", and is more selective in the set of models that's being compared than the standard inclusion BF. Briefly, the inclusion BF across matched models compares:

* all models that include the effect of interest, but NO interactions with the effect of interest, VERSUS
* the models that result from stripping the effect of interest from this set of models.

Let's compare the default inclusion Bayes Factors for all effects:

```{r Inclusion BF default}
# Default inclusion Bayes Factors
kable(inclusionBF(bfKanaiLateral))
```

Doing the analysis this way, we also find strong evidence against most of these effects; particularly the interactions.

My preferred approach is the inclusion Bayes factor across matched models. The evidence is qualitatively similar, but less strong, probably because we aren't including as many poorly fitting models in the model comparison (which have a very large $BF_{10}$ and therefore a lot of effect on the composite Bayes Factor):

```{r Inclusion BF matched models}
kable(inclusionBF(bfKanaiLateral, models = "matched"))
```

### Linear mixed effects matching Kanai - center saccades

```{r Bayes Factor Kanai center}
bfKanaiCenter = anovaBF(latency~stimulation*leg*direction+subject, data = data.frame(filter(latencyMedianBaseline, type == "center")), whichModels="withmain", whichRandom = "subject", progress = FALSE, iterations = 100000) # compute Bayes Factors
bfKanaiCenter <- sort(bfKanaiCenter, decreasing = TRUE) # sort such that winning model is at the top
```

```{r}
kable(select(extractBF(bfKanaiCenter), bf)) # show only the Bayes factors in a table
```

Interestingly, there is a lot more evidence across the board, especially for the models that feature Stimulation and Direction.

```{r Inclusion BF matched models - center saccades}
kable(inclusionBF(bfKanaiCenter, models = "matched"))
```

There seems to be a mismatch with the classical ANOVA: An effect of stimulation receives strong support, whereas it was non-significant. The effect of direction was significant, but it is less strongly supported by the inclusion Bayes Factor (although the evidence still goes in the right direction).

#### Main effect of stimulation

```{r BF Kanai-Center Main effect of stimulation}
latencyMedianBaseline %>%
  filter(type == "center") %>%
  group_by(subject,stimulation) %>%
  summarise(latency = mean(latency)) %>%
  ggplot(aes(stimulation, latency)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  stat_summary(fun.y = mean, geom = "line", aes(group = 1), size = 2) +
  geom_line(aes(colour = subject, group = subject))
```

It is easy to see why this effect is non-significant: the average difference is tiny and there is a lot of variability. The plot shows one major outlier though in terms of the effect size (S01): let's see what happens to the Bayes Factor if we take their data out.

```{r}
latencyNoS01 <- latencyMedianBaseline %>%
  filter(subject != "S01") %>%
  mutate(subject = factor(subject))

bfKanaiCenterNoS01 = anovaBF(latency~stimulation*leg*direction+subject, data = data.frame(filter(latencyNoS01, type == "center")), whichModels="withmain", whichRandom = "subject", progress = FALSE, iterations = 100000) # compute Bayes Factors
bfKanaiCenterNoS01 <- sort(bfKanaiCenterNoS01, decreasing = TRUE) # sort such that winning model is at the top
kable(select(extractBF(bfKanaiCenterNoS01), bf)) # show only the Bayes factors in a table
kable(inclusionBF(bfKanaiCenterNoS01, models = "matched"))
```

This completely abolishes the strong support for Stimulation, and greatly enhances the support for Direction, bringing the Bayesian and the classical ANOVAs more in line.

Still, let's do some follow-up tests with all of the data (i.e. including this subject) to see whether the anodal or cathodal change scores are significantly different from 0 on their own.

Bayesian one-sample t-tests:

```{r Bayesian follow-up test, results='asis'}
latencyMedianBaseline %>%
  filter(type == "center") %>% # keep only center saccades
  group_by(stimulation,subject) %>% # for each session and subject
  summarise(deviation.end = mean(latency)) %>% # average over all other variables
  spread(stimulation,deviation.end) %>% # make separate columns with test data
  summarise_if(is.numeric, funs(extractBF(ttestBF(.), onlybf = TRUE))) %>% # run Bayesian t-test on each column, keeping only the BF
  gather(stimulation,BF,anodal,cathodal) %>% # make row for each stimulation condition
  kable(.)
```

Frequentist one-sample t-tests:

```{r Classical follow-up test, results='asis'}
latencyMedianBaseline %>%
  filter(type == "center") %>% # keep only center saccades
  group_by(stimulation,subject) %>% # for each session and subject
  summarise(deviation.end = mean(latency)) %>% # average over all other variables (df is now still grouped per stimulation)
  summarise_if(is.numeric, funs(list(tidy(t.test(.))))) %>%  # run one-sample t-test for each stimulation condition, return tidy data frames
  unnest() %>% # unpack the list-column with data frame for each test
  kable(.)
```

So neither are actually significant or have a BF with evidence for the alternative.
